{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Final Version of the Fortune Teller for the Halloween Creature Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /srv/conda/envs/notebook/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (2020.10.23)\n",
      "Requirement already satisfied: tqdm in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: click in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (7.1.2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "f=open('FinalData.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase\n",
    "nltk.download('punkt') # first-time use only\n",
    "nltk.download('wordnet') # first-time use only\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    error_m=[\"The spirits are showing me the way... will you be willing to embark on it is another question\", \"It will all work out\",\" Sometimes the best results are worth waiting for\", \"When life throws you a curveball, go play baseball\"]\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+random.choice(error_m)\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can teach you how to bottle fame, brew glory, even put a stopper on failing the semester... I am ZOLTAR\n",
      "Zoltar is a psychic medium eager to answer your questions...\n",
      "Some of the questions you can ask him: What will the weather be like? will i fail the semester? will I get that job?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZOLTAR: hello\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I love sunflowers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZOLTAR: what about love?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I have never been successful everyone leaves me\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZOLTAR: the more you look ahead the more successful you will be.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " thank you zoltar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZOLTAR: thank you.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " can you talk to ghosts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZOLTAR: or we could just talk.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " goodbye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZOLTAR: kiss any free speech goodbye.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZOLTAR: Farewell! May the spirits be with you\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"I can teach you how to bottle fame, brew glory, even put a stopper on failing the semester... I am MADAME \")\n",
    "print(\"Zoltar is a psychic medium eager to answer your questions...\")\n",
    "print(\"Always Begin by saying Hello or Hey. Then tell zoltar what you love the most in the world... End always by saying bye\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"ZOLTAR: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"ZOLTAR: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"ZOLTAR: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ZOLTAR: Farewell! May the spirits be with you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
